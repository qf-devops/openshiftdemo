Setting up Logging and Log Aggregation in OpenShift is key for debugging, auditing, and observability across your cluster. 

OpenShift supports a robust logging stack out of the box and can also integrate with external systems like Elasticsearch, Loki, Splunk, or Cloud-native log processors.

Logging and Log Aggregation in OpenShift

 1. OpenShift Logging Stack (EFK or LokiStack)

OpenShift offers two major logging options:
a. EFK Stack (Elasticsearch, Fluentd, Kibana)
Default stack in many OpenShift versions (up to 4.11+)
* Fluentd collects logs from nodes and containers.
* Elasticsearch stores and indexes logs.
* Kibana visualizes logs.
b. LokiStack (from OpenShift Logging Operator)
Lightweight, Promtail-based alternative to EFK.
* Loki: Log storage and querying backend.
* Promtail: Collects logs.
* Grafana: Used to view logs.

2. Deploying OpenShift Logging (EFK example)

Step 1: Install the Logging Operator
oc apply -f https://raw.githubusercontent.com/openshift/cluster-logging-operator/release-5.6/manifests/4.6/cluster-logging.v5.6.0.clusterserviceversion.yaml
Or via OpenShift Console:
Operators → OperatorHub → Search for "OpenShift Logging" → Install in openshift-logging namespace

Step 2: Deploy the Logging Stack
Create the namespace:
oc create ns openshift-logging
Apply a ClusterLogging custom resource:
apiVersion: "logging.openshift.io/v1"
kind: "ClusterLogging"
metadata:
  name: "instance"
  namespace: "openshift-logging"
spec:
  managementState: "Managed"
  logStore:
    type: "elasticsearch"
    elasticsearch:
      nodeCount: 3
      storage:
        storageClassName: gp2
        size: 200Gi
      resources:
        limits:
          memory: 16Gi
        requests:
          memory: 16Gi
  visualization:
    type: "kibana"
    kibana:
      replicas: 1
  collection:
    logs:
      type: "fluentd"
      fluentd: {}

3. LokiStack Option (lightweight)

Install the Loki Operator:
oc apply -f https://raw.githubusercontent.com/grafana/loki/main/operator/manifest.yaml
Or via OpenShift Web Console → OperatorHub → Search for “Loki”
Deploy LokiStack:
apiVersion: loki.grafana.com/v1
kind: LokiStack
metadata:
  name: lokistack
  namespace: openshift-logging
spec:
  size: 1x.small
  storage:
    schemas:
      - version: v11
        effectiveDate: "2022-06-01"
    secret:
      name: loki-storage-secret
Then deploy Promtail or configure Fluent Bit for log collection.

4. Log Forwarding

You can forward logs to:
* External Elasticsearch
* Splunk
* Syslog
* Cloud log services (e.g., GCP Stackdriver, Azure Log Analytics)
Create a ClusterLogForwarder CR:
apiVersion: "logging.openshift.io/v1"
kind: "ClusterLogForwarder"
metadata:
  name: "instance"
  namespace: "openshift-logging"
spec:
  outputs:
    - name: elastic
      type: "elasticsearch"
      url: "https://external-es.example.com:9200"
  pipelines:
    - name: forward-to-external
      inputRefs:
        - application
      outputRefs:
        - elastic

5. Viewing Logs

* OpenShift Console: Observe → Logs
* Kibana: Accessible via route in openshift-logging
* Grafana (with Loki): View logs using log labels and time filters

6. Best Practices

* Centralize logs in multi-cluster setups using log aggregation tools.
* Apply retention policies for log indices.
* Use log levels effectively in applications (INFO, WARN, ERROR).
* Mask sensitive info in logs (GDPR, HIPAA compliance).
* Monitor log ingestion performance.
* Archive logs if needed (e.g., AWS S3 or GCS)
